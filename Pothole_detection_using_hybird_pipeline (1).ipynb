{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VpRVfK4tV8Zo"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "import torch.distributed as dist\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
        "from torchvision.transforms import transforms\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "# Set up environment variables\n",
        "os.environ['MASTER_ADDR'] = 'localhost'\n",
        "os.environ['MASTER_PORT'] = '12355'\n",
        "\n",
        "# Initialize process group\n",
        "num_gpus = torch.cuda.device_count()\n",
        "dist.init_process_group(backend='nccl', world_size=num_gpus, rank=torch.cuda.current_device())\n",
        "\n",
        "# Define paths\n",
        "data_path = '/path/to/your/dataset'-------------------------------------------------->Pothole Annotated dataset\n",
        "train_annotations = os.path.join(data_path, 'train_annotations.json')\n",
        "val_annotations = os.path.join(data_path, 'val_annotations.json')\n",
        "\n",
        "# Hyperparameters\n",
        "batch_size = 8\n",
        "num_epochs = 50\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Data preprocessing\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "transforms.RandomHorizontalFlip(),\n",
        "transforms.ToTensor(),\n",
        "transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "])\n",
        "\n",
        "\n",
        "train_data = datasets.CocoDetection(root=os.path.join(data_path, 'train'), annFile=train_annotations, transform=transform)\n",
        "val_data = datasets.CocoDetection(root=os.path.join(data_path, 'val'), annFile=val_annotations, transform=transform)\n",
        "\n",
        "train_sampler = DistributedSampler(train_data, num_replicas=num_gpus, rank=torch.cuda.current_device())\n",
        "val_sampler = DistributedSampler(val_data, num_replicas=num_gpus, rank=torch.cuda.current_device())\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, sampler=train_sampler, num_workers=4)\n",
        "val_loader = DataLoader(val_data, batch_size=batch_size, sampler=val_sampler, num_workers=4)\n",
        "\n",
        "device = torch.device(f'cuda:{torch.cuda.current_device()}')\n",
        "model = fasterrcnn_resnet50_fpn(pretrained=False, num_classes=2).to(device)\n",
        "model = nn.parallel.DistributedDataParallel(model, device_ids=[torch.cuda.current_device()])\n",
        "oss function and optimizer\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = optim.SGD(params, lr=learning_rate, momentum=0.9, weight_decay=0.0005)\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "model.train()\n",
        "train_sampler.set_epoch(epoch)\n",
        "running_loss = 0.0\n",
        "for i, (inputs, targets) in enumerate(train_loader):\n",
        "    inputs = list(img.to(device) for img in inputs)\n",
        "    targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    losses = model(inputs, targets)\n",
        "    loss = sum(l for l in losses.values())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  running_loss += loss.item()\n",
        "print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
        "\n",
        "# Validate the model\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, targets in val_loader:\n",
        "        inputs = list(img.to(device) for img in inputs)\n",
        "targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        " outputs = model(inputs)\n",
        "      for idx, output in enumerate(outputs):\n",
        "            gt_boxes = targets[idx]['boxes']\n",
        "            pred_boxes = output['boxes']\n",
        "\n",
        "      for gt_box in gt_boxes:\n",
        "           for pred_box in pred_boxes:\n",
        "                iou = get_iou(gt_box, pred_box)\n",
        "              if iou >= 0.5:\n",
        "                    correct += 1\n",
        "                      break\n",
        "        total += sum([len(t['boxes']) for t in targets])\n",
        "\n",
        "print(f\"Validation accuracy: {100 * correct / total:.2f}%\")\n",
        "\n",
        "torch.save(model.module.state_dict(), \"pothole_detector.pth\")\n",
        "\n",
        "def get_iou(boxA, boxB):\n",
        "# Determine the (x, y)-coordinates of the intersection rectangle\n",
        "xA = max(boxA[0], boxB[0])\n",
        "yA = max(boxA[1], boxB[1])\n",
        "xB = min(boxA[2], boxB[2])\n",
        "yB = min(boxA[3], boxB[3])\n",
        "max(0, yB - yA + 1)\n",
        "boxA_area = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
        "boxB_area = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
        "iou = inter_area / float(boxA_area + boxB_area - inter_area)\n",
        "\n",
        "return iou\n"
      ]
    }
  ]
}